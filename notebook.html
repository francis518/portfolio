{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Model Evaluation for Alumni-Obituary Matching\n",
    "\n",
    "This notebook evaluates multiple AI models based on their ability to match alumni with obituary records.  \n",
    "The evaluation considers precision, recall, and F1 score.  \n",
    "\n",
    "## Steps:\n",
    "1. Load and preprocess alumni and obituary data  \n",
    "2. Apply various matching techniques  \n",
    "3. Evaluate performance using metrics  \n",
    "4. Compare different AI models  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Code is required to be run in sequence.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structuring Alumni Data\n",
    "\n",
    "The following class helps structure alumni records from a CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlumniRecord:\n",
    "    def __init__(self, data):\n",
    "        self.name = data.get(\"NAME\", \"\")\n",
    "        self.born = data.get(\"BORN\", \"\")\n",
    "        self.first_name = data.get(\"FIRST\", \"\")\n",
    "        self.middle_name = data.get(\"MIDDLE\", \"\")\n",
    "        self.last_name = data.get(\"LAST\", \"\")\n",
    "        self.other_name = data.get(\"OTHER_NAME\", \"\")\n",
    "        self.prefix = data.get(\"PREFIX\", \"\")\n",
    "        self.suffix = data.get(\"SUFFIX\", \"\")\n",
    "        self.maiden_name = data.get(\"MAIDEN\", \"\")\n",
    "        self.gender = data.get(\"GENDER\", \"\")\n",
    "        self.age = data.get(\"AGE\", \"\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"AlumniRecord(Name={self.first_name} {self.middle_name} {self.last_name}, Age={self.age})\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Alumni Data\n",
    "\n",
    "The `read_alumni_data` function reads a CSV file containing alumni records and returns a list of `AlumniRecord` objects. This function handles missing values by filling them with empty strings and ensures that all data is treated as strings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_alumni_data(file_path):\n",
    "    df = pd.read_csv(file_path, dtype=str, encoding='ISO-8859-1')\n",
    "\n",
    "    df = df.fillna(\"\")  \n",
    "\n",
    "    alumni_records = [AlumniRecord(row) for _, row in df.iterrows()]\n",
    "    return alumni_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(alumni_records, output_file=\"alumni_data.json\"):\n",
    "    alumni_json = json.dumps([record.__dict__ for record in alumni_records], indent=4)\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(alumni_json)\n",
    "    print(f\"Saved {len(alumni_records)} alumni records as JSON.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obituary Records\n",
    "\n",
    "This section defines the ObituaryRecord class, which represents each obituary record and includes various personal and family details about the deceased individual. The class allows us to store fields such as ID, NAME, BIRTHDATE, and DEATHDATE. These records can then be compared with alumni records to identify possible matches.\n",
    "\n",
    "We also create a function to read the obituary data from an Excel file, followed by parsing the records into objects for further matching and analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObituaryRecord:\n",
    "    def __init__(self, data):\n",
    "        self.name = data.get(\"NAME\", \"\")\n",
    "        self.born = data.get(\"BORN\", \"\")\n",
    "        self.first_name = data.get(\"FIRST\", \"\")\n",
    "        self.middle_name = data.get(\"MIDDLE\", \"\")\n",
    "        self.last_name = data.get(\"LAST\", \"\")\n",
    "        self.other_name = data.get(\"OTHER_NAME\", \"\")\n",
    "        self.prefix = data.get(\"PREFIX\", \"\")\n",
    "        self.suffix = data.get(\"SUFFIX\", \"\")\n",
    "        self.maiden_name = data.get(\"MAIDEN\", \"\")\n",
    "        self.gender = data.get(\"GENDER\", \"\")\n",
    "        self.age = data.get(\"AGE\", \"\")\n",
    "        self.match = data.get(\"MATCH\", \"\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"ObituaryRecord(Name={self.first_name} {self.middle_name} {self.last_name}, Age={self.age}, Match={self.match})\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read_obituary_data: This function is responsible for reading an Excel file containing obituary data and converting each row into an ObituaryRecord object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_obituary_data(file_path):\n",
    "    df = pd.read_csv(file_path, dtype=str, encoding='ISO-8859-1')\n",
    "\n",
    "    df = df.fillna(\"\")  \n",
    "\n",
    "    obituary_records = [ObituaryRecord(row) for _, row in df.iterrows()]\n",
    "    return obituary_records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(obituary_records, output_file=\"obituary_data.json\"):\n",
    "    obituary_json = json.dumps([record.__dict__ for record in obituary_records], indent=4)\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(obituary_json)\n",
    "    print(f\"Saved {len(obituary_records)} obituary records as JSON.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alumniRecord import read_alumni_data\n",
    "from obituaryRecord import read_obituary_data\n",
    "from utils import save_to_json\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    alumni_file = \"matching_database.csv\"\n",
    "    obituary_file = \"matching_verification_dataset.csv\"\n",
    "\n",
    "    alumni_records = read_alumni_data(alumni_file)\n",
    "    obituary_records = read_obituary_data(obituary_file)\n",
    "\n",
    "    \n",
    "    save_to_json(alumni_records, \"alumni_data.json\")\n",
    "    save_to_json(obituary_records, \"obituary_data.json\")\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison (chatgpt and gemini)\n",
    "This code processes the matched alumni and obituary records using the selected model (ChatGPT or Gemini). It generates a confidence score and a match status for each pair and saves the results to a CSV file.\n",
    "\n",
    "The output will be saved as chatgpt_results.csv or gemini_results.csv depending on the model used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Matching for Initial Filtering\n",
    " - Before sending data to the any AI model, the script performs fuzzy matching to identify potential candidate records.\n",
    "\n",
    " - Uses fuzzy string matching (e.g., Levenshtein distance or Jaro-Winkler similarity) to compare obituary names with alumni names.\n",
    "\n",
    " - If a name similarity exceeds a certain threshold (e.g., 60% similarity), the record is considered a potential match and processed further.\n",
    "\n",
    " - This step helps reduce the number of API calls by filtering out unlikely matches early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "from google import genai\n",
    "from openai import OpenAI\n",
    "\n",
    "from tabulate import tabulate\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import re \n",
    "import csv\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "chatgpt_api_key = os.getenv(\"CHAT_GPT_API_KEY\")\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=chatgpt_api_key)\n",
    "gemini_client = genai.Client(api_key=gemini_api_key)\n",
    "\n",
    "def fuzzy_match(target_name, alumni_records, threshold=60):\n",
    "    names = [f\"{record.get('first_name', '')} {record.get('last_name', '')}\" for record in alumni_records]\n",
    "    matches = process.extract(target_name, names, limit=5)\n",
    "\n",
    "    print(\"Matched Alumni Records (Full Information):\")\n",
    "    matched_records = []\n",
    "    \n",
    "    for match in matches:\n",
    "        if match[1] >= threshold:\n",
    "            matched_name = match[0]\n",
    "\n",
    "            matched_record = next((record for record in alumni_records if f\"{record.get('first_name', '')} {record.get('last_name', '')}\" == matched_name), None)\n",
    "            \n",
    "            if matched_record is not None:\n",
    "                matched_records.append(matched_record)\n",
    "                print(json.dumps(matched_record, indent=4))\n",
    "            else:\n",
    "                print(f\"No match found for {matched_name}\")\n",
    "    \n",
    "    return matched_records\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"alumni_data.json\", \"r\") as f:\n",
    "    alumni_records = json.load(f)\n",
    "\n",
    "with open(\"obituary_data.json\", \"r\") as f:\n",
    "    obituary_records = json.load(f)\n",
    "    \n",
    "    \n",
    "model_choice = \"gemini\"  \n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "def generate_prompt(alumni, obituary):\n",
    "    return f\"\"\"\n",
    "    You are an expert in data matching and entity resolution. Given two datasets—one containing alumni records and another containing obituary records—your task is to determine if a given obituary record matches an alumni record.\n",
    "\n",
    "    **Guidelines for Comparison:**\n",
    "    - Start with a baseline confidence score of **100%**.\n",
    "    - Prioritize **primary identifiers**: Last Name (highest weight), First Name (high weight), Middle Name (moderate weight).\n",
    "    - Adjust the confidence score by **subtracting penalties** for mismatches:\n",
    "        - Last Name mismatches should carry a strong penalty.\n",
    "        - First Name mismatches should carry a high penalty.\n",
    "        - Middle Name mismatches should carry a moderate penalty.\n",
    "    - Use **secondary identifiers** (e.g., birthdate, age, gender) to refine the score:\n",
    "        - Birth year and age discrepancies should reduce confidence moderately.\n",
    "        - Gender mismatches should reduce confidence moderately.\n",
    "        - Maiden name mismatches should carry a smaller penalty.\n",
    "    - Some obituary records **may not match** any alumni records—return 'No Match' when appropriate.\n",
    "\n",
    "    **Scoring & Decision Rules:**\n",
    "    - Start with a confidence score of **100%**.\n",
    "    - Directly subtract penalties based on the type and severity of mismatches.\n",
    "    - Ensure the final confidence score reflects the cumulative penalties.\n",
    "    - If the final confidence score is negative, set it to **0%**.\n",
    "    - If confidence is **70% or higher**, classify it as a 'Match.'\n",
    "    - If confidence is **below 70%**, classify it as 'No Match.'\n",
    "\n",
    "    **Alumni Record:**\n",
    "    Name: {alumni.get('name', 'N/A')}\n",
    "    Born: {alumni.get('born', 'N/A')}\n",
    "    First Name: {alumni.get('first_name', 'N/A')}\n",
    "    Middle Name: {alumni.get('middle_name', 'N/A')}\n",
    "    Last Name: {alumni.get('last_name', 'N/A')}\n",
    "    Maiden Name: {alumni.get('maiden_name', 'N/A')}\n",
    "    Gender: {alumni.get('gender', 'N/A')}\n",
    "    Age: {alumni.get('age', 'N/A')}\n",
    "\n",
    "    **Obituary Record:**\n",
    "    Name: {obituary.get('name', 'N/A')}\n",
    "    Born: {obituary.get('born', 'N/A')}\n",
    "    First Name: {obituary.get('first_name', 'N/A')}\n",
    "    Middle Name: {obituary.get('middle_name', 'N/A')}\n",
    "    Last Name: {obituary.get('last_name', 'N/A')}\n",
    "    Maiden Name: {obituary.get('maiden_name', 'N/A')}\n",
    "    Gender: {obituary.get('gender', 'N/A')}\n",
    "    Age: {obituary.get('age', 'N/A')}\n",
    "\n",
    "    **Your task:**\n",
    "    - Provide a single final confidence score between **0% and 100%**.  \n",
    "    - Write a clear explanation of how the score was calculated.  \n",
    "    - Return the result in this exact format:  \n",
    "\n",
    "    ```\n",
    "    Confidence Score: [confidence value]%  \n",
    "    Decision: [Match/No Match]  \n",
    "    Explanation: [summary of how the score was determined]  \n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "def save_results_to_csv(results, filename=\"gemini_results.csv\"):\n",
    "    with open(filename, \"w\", newline=\"\") as csvfile:\n",
    "        fieldnames = [\"Alumni Name\", \"Obituary Name\", \"Confidence Score\", \"Match Status\", \"Explanation\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "\n",
    "        for result in results:\n",
    "            writer.writerow({\n",
    "                \"Alumni Name\": result[0],\n",
    "                \"Obituary Name\": result[1],\n",
    "                \"Confidence Score\": result[2],\n",
    "                \"Match Status\": result[3],\n",
    "                \"Explanation\": result[4]\n",
    "            })\n",
    " \n",
    "    \n",
    "    \n",
    "def call_gemini(contents):\n",
    "    response = gemini_client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=contents\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "\n",
    "def call_chatgpt(contents):\n",
    "    response = client.chat.completions.create(model=\"gpt-4o-mini\",  # Or use another ChatGPT model if needed\n",
    "    messages=[{\"role\": \"system\", \"content\": \"You are an expert in data matching.\"},\n",
    "              {\"role\": \"user\", \"content\": contents}])\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "\n",
    "def extract_confidence_score(response_text):\n",
    "    match = re.findall(r\"(Confidence Score|Final Confidence Score|Confidence):\\s*(\\d+(\\.\\d+)?)\\s*%\", response_text)\n",
    "    if match:\n",
    "        return max(0, min(100, float(match[-1][1])))\n",
    "    return 10  # Default score if nothing is found\n",
    "\n",
    "\n",
    "\n",
    "def process_with_model(model_choice, retries=3):\n",
    "    if not obituary_records:\n",
    "        print(\"No obituary records found.\")\n",
    "        return\n",
    "    \n",
    "    selected_obituaries = obituary_records[:10]\n",
    " \n",
    "    for obituary in selected_obituaries:\n",
    "        last_result = None\n",
    "        match_found = False\n",
    "\n",
    "        # Get a shortlist of alumni records using fuzzy matching\n",
    "        matched_alumni_records = fuzzy_match(obituary.get('name', ''), alumni_records)\n",
    "        \n",
    "        for alumni in matched_alumni_records:\n",
    "            contents = generate_prompt(alumni, obituary)\n",
    "\n",
    "            for attempt in range(retries):\n",
    "                try:\n",
    "                    if model_choice == \"gemini\":\n",
    "                        response_text = call_gemini(contents)\n",
    "                    elif model_choice == \"chatgpt\":\n",
    "                        response_text = call_chatgpt(contents)\n",
    "                    else:\n",
    "                        raise ValueError(\"Unknown model choice.\")\n",
    "\n",
    "                    confidence_score = extract_confidence_score(response_text)\n",
    "                    match_status = \"Match\" if confidence_score >= 70 else \"No Match\"\n",
    "                    \n",
    "                    explanation = \"\"\n",
    "                    for line in response_text.split(\"\\n\"):\n",
    "                        line = line.strip()\n",
    "                        if \"Confidence Score:\" not in line:\n",
    "                            explanation += line + \" \"\n",
    "\n",
    "                    last_result = [\n",
    "                        alumni.get('name', ''),\n",
    "                        obituary.get('name', ''),\n",
    "                        confidence_score,\n",
    "                        match_status,\n",
    "                        explanation.strip()\n",
    "                    ]\n",
    "\n",
    "                    if confidence_score >= 70:\n",
    "                        print(f\"Match found for Obituary and Alumni with Confidence: {confidence_score}%\")\n",
    "                        results.append(last_result)\n",
    "                        match_found = True\n",
    "                        break  # Stop processing once a match is found\n",
    "                    \n",
    "                    time.sleep(1)\n",
    "                    break\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing: {str(e)}\")\n",
    "                    if attempt == retries - 1:\n",
    "                        last_result = [alumni.get('name', ''), obituary.get('name', ''), \"Error\", \"No Match\", str(e)]\n",
    "                    time.sleep(2**attempt)  # Exponential backoff\n",
    "            \n",
    "            if match_found:\n",
    "                break\n",
    "\n",
    "        if last_result and last_result[3] == \"No Match\":\n",
    "            print(f\"No match found for last comparison with Confidence: {last_result[2]}%\")\n",
    "            results.append(last_result)\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "print(f\"Processing with {model_choice.capitalize()} model...\")\n",
    "process_with_model(model_choice)\n",
    "save_results_to_csv(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Matching with DeepSeek AI\n",
    "\n",
    "This script compares alumni records with obituary records using the DeepSeek AI model to determine possible matches. It follows these steps:\n",
    "\n",
    "### **Setup and Initialization**\n",
    "- Loads environment variables from `.env` file for API key.\n",
    "- Reads alumni and obituary data from `alumni_data.json` and `obituary_data.json`.\n",
    "- Creates a dictionary for quick lookup of obituary records.\n",
    "\n",
    "### **Prompt Generation**\n",
    "- Constructs a detailed prompt that includes:\n",
    "  - **Primary identifiers**: Last Name, First Name, Middle Name  \n",
    "  - **Secondary identifiers**: Age, Birth Year, City of Death, University, etc.  \n",
    "  - Scoring rules where a confidence score ≥ 70% indicates a match.  \n",
    "\n",
    "### **Model Interaction**\n",
    "- Sends the prompt to the DeepSeek AI model using the OpenAI client.\n",
    "- Handles response extraction and error retries.\n",
    "\n",
    "### **Processing and Results**\n",
    "- Extracts the confidence score and explanation from the model’s response.\n",
    "- Classifies the result as a \"Match\" or \"No Match.\"\n",
    "- Appends the result to a list.\n",
    "\n",
    "### **Output**\n",
    "- Outputs the results as:\n",
    "  - A table printed to the console using `tabulate`.  \n",
    "  - A CSV file (`deepseek_results.csv`).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import faiss\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import csv\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "client = openai.OpenAI(api_key=API_KEY, base_url=\"https://api.deepseek.com/v1\")\n",
    "\n",
    "\n",
    "def fuzzy_match(target_name, alumni_records, threshold=60):\n",
    "    names = [f\"{record.get('first_name', '')} {record.get('last_name', '')}\" for record in alumni_records]\n",
    "    matches = process.extract(target_name, names, limit=5)\n",
    "\n",
    "    print(\"Matched Alumni Records (Full Information):\")\n",
    "    matched_records = []\n",
    "    \n",
    "    for match in matches:\n",
    "        if match[1] >= threshold:\n",
    "            matched_name = match[0]\n",
    "           \n",
    "            # Find the matched record\n",
    "            matched_record = next((record for record in alumni_records if f\"{record.get('first_name', '')} {record.get('last_name', '')}\" == matched_name), None)\n",
    "            \n",
    "            if matched_record is not None:\n",
    "                matched_records.append(matched_record)\n",
    "                print(json.dumps(matched_record, indent=4))\n",
    "            else:\n",
    "                print(f\"No match found for {matched_name}\")\n",
    "    \n",
    "    return matched_records\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_results_to_csv(results, filename=\"deepseek_results.csv\"):\n",
    "    with open(filename, \"w\", newline=\"\") as csvfile:\n",
    "        fieldnames = [\"Alumni Name\", \"Obituary Name\", \"Confidence Score\", \"Match Status\", \"Explanation\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "\n",
    "        for result in results:\n",
    "            writer.writerow({\n",
    "                \"Alumni Name\": result[0],\n",
    "                \"Obituary Name\": result[1],\n",
    "                \"Confidence Score\": result[2],\n",
    "                \"Match Status\": result[3],\n",
    "                \"Explanation\": result[4]\n",
    "            })\n",
    "\n",
    "\n",
    "def generate_prompt(alumni, obituary):\n",
    "    return f\"\"\"\n",
    "    You are an expert in data matching and entity resolution. Given two datasets—one containing alumni records and another containing obituary records—your task is to determine if a given obituary record matches an alumni record.\n",
    "\n",
    "    **Guidelines for Comparison:**\n",
    "    - Start with a baseline confidence score of **100%**.\n",
    "    - Prioritize **primary identifiers**: Last Name (highest weight), First Name (high weight), Middle Name (moderate weight).\n",
    "    - Adjust the confidence score by **subtracting penalties** for mismatches:\n",
    "        - Last Name mismatches should carry a strong penalty.\n",
    "        - First Name mismatches should carry a high penalty.\n",
    "        - Middle Name mismatches should carry a moderate penalty.\n",
    "    - Use **secondary identifiers** (e.g., birthdate, age, gender) to refine the score:\n",
    "        - Birth year and age discrepancies should reduce confidence moderately.\n",
    "        - Gender mismatches should reduce confidence moderately.\n",
    "        - Maiden name mismatches should carry a smaller penalty.\n",
    "    - Some obituary records **may not match** any alumni records—return 'No Match' when appropriate.\n",
    "\n",
    "    **Scoring & Decision Rules:**\n",
    "    - Start with a confidence score of **100%**.\n",
    "    - Directly subtract penalties based on the type and severity of mismatches.\n",
    "    - Ensure the final confidence score reflects the cumulative penalties.\n",
    "    - If the final confidence score is negative, set it to **0%**.\n",
    "    - If confidence is **70% or higher**, classify it as a 'Match.'\n",
    "    - If confidence is **below 70%**, classify it as 'No Match.'\n",
    "\n",
    "    **Alumni Record:**\n",
    "    Name: {alumni.get('name', 'N/A')}\n",
    "    Born: {alumni.get('born', 'N/A')}\n",
    "    First Name: {alumni.get('first_name', 'N/A')}\n",
    "    Middle Name: {alumni.get('middle_name', 'N/A')}\n",
    "    Last Name: {alumni.get('last_name', 'N/A')}\n",
    "    Maiden Name: {alumni.get('maiden_name', 'N/A')}\n",
    "    Gender: {alumni.get('gender', 'N/A')}\n",
    "    Age: {alumni.get('age', 'N/A')}\n",
    "\n",
    "    **Obituary Record:**\n",
    "    Name: {obituary.get('name', 'N/A')}\n",
    "    Born: {obituary.get('born', 'N/A')}\n",
    "    First Name: {obituary.get('first_name', 'N/A')}\n",
    "    Middle Name: {obituary.get('middle_name', 'N/A')}\n",
    "    Last Name: {obituary.get('last_name', 'N/A')}\n",
    "    Maiden Name: {obituary.get('maiden_name', 'N/A')}\n",
    "    Gender: {obituary.get('gender', 'N/A')}\n",
    "    Age: {obituary.get('age', 'N/A')}\n",
    "\n",
    "    **Your task:**\n",
    "    - Provide a single final confidence score between **0% and 100%**.  \n",
    "    - Write a clear explanation of how the score was calculated.  \n",
    "    - Return the result in this exact format:  \n",
    "\n",
    "    ```\n",
    "    Confidence Score: [confidence value]%  \n",
    "    Decision: [Match/No Match]  \n",
    "    Explanation: [summary of how the score was determined]  \n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Call DeepSeek API\n",
    "# -----------------------------\n",
    "def call_deepseek(contents):\n",
    "    # Make the API request to DeepSeek to compare records\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[ \n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in data matching.\"},\n",
    "            {\"role\": \"user\", \"content\": contents}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def extract_confidence_score(response_text):\n",
    "    match = re.findall(r\"(Confidence Score|Final Confidence Score|Confidence):\\s*(\\d+(\\.\\d+)?)\\s*%\", response_text)\n",
    "    if match:\n",
    "        return max(0, min(100, float(match[-1][1])))\n",
    "    return 10  # Default score if nothing is found\n",
    "\n",
    "\n",
    "\n",
    "def process_with_deepseek(retries=3, top_k=5):\n",
    "    if not obituary_records:\n",
    "        print(\"No obituary records found.\")\n",
    "        return\n",
    "    \n",
    "    selected_obituaries = obituary_records[:200]\n",
    "    \n",
    "    for obituary in selected_obituaries:\n",
    "        last_result = None\n",
    "        match_found = False\n",
    "  # Get a short list of alumni records based on fuzzy matching with the obituary name\n",
    "        matched_alumni_records = fuzzy_match(obituary.get('name', ''), alumni_records)\n",
    "        \n",
    "        for alumni in matched_alumni_records:  \n",
    "            contents = generate_prompt(alumni, obituary)\n",
    "\n",
    "            for attempt in range(retries):\n",
    "                try:\n",
    "                    response_text = call_deepseek(contents)\n",
    "\n",
    "                    confidence_score = extract_confidence_score(response_text)\n",
    "                    match_status = \"Match\" if confidence_score >= 70 else \"No Match\"\n",
    "\n",
    "                    explanation = \"\"\n",
    "                    for line in response_text.split(\"\\n\"):\n",
    "                        line = line.strip()\n",
    "                        if \"Confidence Score:\" in line:\n",
    "                            continue\n",
    "                        else:\n",
    "                            explanation += line + \" \"\n",
    "\n",
    "                    last_result = [ \n",
    "                        alumni.get('name', ''),\n",
    "                        obituary.get('name', ''),\n",
    "                        confidence_score,\n",
    "                        match_status,\n",
    "                        explanation.strip()\n",
    "                    ]\n",
    "                    if confidence_score >= 70:\n",
    "                        print(f\"Match found for Obituary and Alumni with Confidence: {confidence_score}%\")\n",
    "                        results.append(last_result)\n",
    "                        match_found = True\n",
    "                        break  \n",
    "                        \n",
    "                    time.sleep(1)\n",
    "                    break\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing: {str(e)}\")\n",
    "                    if attempt == retries - 1:\n",
    "                        last_result = [\"Error\", \"No Match\", str(e)]\n",
    "                    time.sleep(2**attempt)\n",
    "            \n",
    "            if match_found:\n",
    "                break\n",
    "\n",
    "        if last_result and last_result[3] == \"No Match\":\n",
    "            print(f\"No match found for last comparison with Confidence: {last_result[2]}%\")\n",
    "            results.append(last_result)\n",
    "            \n",
    "            \n",
    "\n",
    "with open(\"alumni_data.json\", \"r\") as f:\n",
    "    alumni_records = json.load(f)\n",
    "\n",
    "with open(\"obituary_data.json\", \"r\") as f:\n",
    "    obituary_records = json.load(f)\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "process_with_deepseek()\n",
    "save_results_to_csv(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Matching with Groq AI\n",
    "\n",
    "This script compares alumni records with obituary records using the Groq LLaMA3 model.\n",
    "\n",
    "### **Setup**  \n",
    "- Reads alumni and obituary data from JSON files.  \n",
    "\n",
    "### **Prompt Generation**  \n",
    "- Builds a prompt using key identifiers:  \n",
    "  - **Primary:** First Name, Last Name, Middle Name  \n",
    "  - **Secondary:** Age, Birth Year, City of Death, University, etc.  \n",
    "- Confidence score ≥ 70% → **\"Match\"**; otherwise **\"No Match.\"**  \n",
    "\n",
    "### **Model Interaction**  \n",
    "- Sends the prompt to the Groq model.  \n",
    "- Extracts confidence score, match status, and explanation.  \n",
    "\n",
    "### **Output**  \n",
    "- Prints results in a table.  \n",
    "- Saves to CSV and text files.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from fuzzywuzzy import process\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Load JSON data\n",
    "with open(\"alumni_data.json\", \"r\") as f:\n",
    "    alumni_records = json.load(f)\n",
    "\n",
    "with open(\"obituary_data.json\", \"r\") as f:\n",
    "    obituary_records = json.load(f)\n",
    "\n",
    "def extract_confidence_and_explanation(response_text):\n",
    "    try:\n",
    "        confidence_match = re.search(r\"Confidence Score[:\\s]*([\\d]{1,3})\\%\", response_text)\n",
    "        if not confidence_match:\n",
    "            confidence_match = re.search(r\"(\\d{1,3})%\", response_text)\n",
    "\n",
    "        confidence_score = int(confidence_match.group(1)) if confidence_match else 0\n",
    "        match_status = \"Match\" if confidence_score >= 70 else \"No Match\"\n",
    "\n",
    "        explanation_match = re.search(r\"\\*\\*Explanation:\\*\\*\\s*(.*)\", response_text, re.DOTALL)\n",
    "        explanation = explanation_match.group(1).strip() if explanation_match else response_text.strip()\n",
    "\n",
    "        return confidence_score, match_status, explanation\n",
    "    except Exception as e:\n",
    "        return \"Error\", \"Error\", f\"Error extracting data: {e}\"\n",
    "\n",
    "def call_groq(contents):\n",
    "    url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "    headers = {\"Authorization\": f\"Bearer {groq_api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"model\": \"llama3-8b-8192\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in data matching.\"},\n",
    "            {\"role\": \"user\", \"content\": contents}\n",
    "        ],\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "        response_json = response.json()\n",
    "        if \"choices\" not in response_json or not response_json[\"choices\"]:\n",
    "            raise ValueError(\"Unexpected response format: Missing 'choices' field.\")\n",
    "        result_text = response_json[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        return extract_confidence_and_explanation(result_text)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return \"Error\", \"Error\", f\"Request error: {e}\"\n",
    "    except Exception as e:\n",
    "        return \"Error\", \"Error\", f\"Error parsing API response: {e}\"\n",
    "\n",
    "def fuzzy_match(target_name, alumni_records, threshold=60):\n",
    "    names = [f\"{record.get('first_name', '')} {record.get('last_name', '')}\" for record in alumni_records]\n",
    "    matches = process.extract(target_name, names, limit=5)\n",
    "\n",
    "    matched_records = []\n",
    "    for match in matches:\n",
    "        if match[1] >= threshold:\n",
    "            matched_name = match[0]\n",
    "            matched_record = next((record for record in alumni_records if f\"{record.get('first_name', '')} {record.get('last_name', '')}\" == matched_name), None)\n",
    "            if matched_record is not None:\n",
    "                matched_records.append(matched_record)\n",
    "                print(json.dumps(matched_record, indent=4))\n",
    "    return matched_records\n",
    "\n",
    "\n",
    "def generate_prompt(alumni, obituary):\n",
    "    return f\"\"\"\n",
    "    You are an expert in data matching and entity resolution. Given two datasets—one containing alumni records and another containing obituary records—your task is to determine if a given obituary record matches an alumni record.\n",
    "\n",
    "    **Guidelines for Comparison:**\n",
    "    - Start with a baseline confidence score of **100%**.\n",
    "    - Prioritize **primary identifiers**: Last Name (highest weight), First Name (high weight), Middle Name (moderate weight).\n",
    "    - Adjust the confidence score by **subtracting penalties** for mismatches:\n",
    "        - Last Name mismatches should carry a strong penalty.\n",
    "        - First Name mismatches should carry a high penalty.\n",
    "        - Middle Name mismatches should carry a moderate penalty.\n",
    "    - Use **secondary identifiers** (e.g., birthdate, age, gender) to refine the score:\n",
    "        - Birth year and age discrepancies should reduce confidence moderately.\n",
    "        - Gender mismatches should reduce confidence moderately.\n",
    "        - Maiden name mismatches should carry a smaller penalty.\n",
    "    - Some obituary records **may not match** any alumni records—return 'No Match' when appropriate.\n",
    "\n",
    "    **Scoring & Decision Rules:**\n",
    "    - Start with a confidence score of **100%**.\n",
    "    - Directly subtract penalties based on the type and severity of mismatches.\n",
    "    - Ensure the final confidence score reflects the cumulative penalties.\n",
    "    - If the final confidence score is negative, set it to **0%**.\n",
    "    - If confidence is **70% or higher**, classify it as a 'Match.'\n",
    "    - If confidence is **below 70%**, classify it as 'No Match.'\n",
    "\n",
    "    **Alumni Record:**\n",
    "    Name: {alumni.get('name', 'N/A')}\n",
    "    Born: {alumni.get('born', 'N/A')}\n",
    "    First Name: {alumni.get('first_name', 'N/A')}\n",
    "    Middle Name: {alumni.get('middle_name', 'N/A')}\n",
    "    Last Name: {alumni.get('last_name', 'N/A')}\n",
    "    Maiden Name: {alumni.get('maiden_name', 'N/A')}\n",
    "    Gender: {alumni.get('gender', 'N/A')}\n",
    "    Age: {alumni.get('age', 'N/A')}\n",
    "\n",
    "    **Obituary Record:**\n",
    "    Name: {obituary.get('name', 'N/A')}\n",
    "    Born: {obituary.get('born', 'N/A')}\n",
    "    First Name: {obituary.get('first_name', 'N/A')}\n",
    "    Middle Name: {obituary.get('middle_name', 'N/A')}\n",
    "    Last Name: {obituary.get('last_name', 'N/A')}\n",
    "    Maiden Name: {obituary.get('maiden_name', 'N/A')}\n",
    "    Gender: {obituary.get('gender', 'N/A')}\n",
    "    Age: {obituary.get('age', 'N/A')}\n",
    "\n",
    "    **Your task:**\n",
    "    - Provide a single final confidence score between **0% and 100%**.  \n",
    "    - Write a clear explanation of how the score was calculated.  \n",
    "    - Return the result in this exact format:  \n",
    "\n",
    "    ```\n",
    "    Confidence Score: [confidence value]%  \n",
    "    Decision: [Match/No Match]  \n",
    "    Explanation: [summary of how the score was determined]  \n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def process_with_groq(retries=3, top_k=5):\n",
    "    if not obituary_records:\n",
    "        print(\"No obituary records found.\")\n",
    "        return\n",
    "    \n",
    "    selected_obituaries = obituary_records[:200]\n",
    "    \n",
    "    for obituary in selected_obituaries:\n",
    "        match_found = False\n",
    "        last_result = None\n",
    "        \n",
    "        matched_alumni_records = fuzzy_match(obituary.get('name', ''), alumni_records)\n",
    "        \n",
    "        for alumni in matched_alumni_records:\n",
    "            if match_found:  \n",
    "                break\n",
    "            \n",
    "            contents = generate_prompt(alumni, obituary)\n",
    "\n",
    "            for attempt in range(retries):\n",
    "                try:\n",
    "                    confidence, match_status, _ = call_groq(contents)\n",
    "\n",
    "                    if confidence != \"Error\" and confidence >= 50:\n",
    "                        print(f\"Match found for Obituary and Alumni with Confidence: {confidence}%\")\n",
    "                        last_result = [\n",
    "                            alumni.get('first_name', '') + \" \" + alumni.get('last_name', ''),\n",
    "                            obituary.get('name', ''),\n",
    "                            confidence,\n",
    "                            match_status\n",
    "                        ]\n",
    "                        results.append(last_result)\n",
    "                        match_found = True\n",
    "                        break\n",
    "                    \n",
    "                    time.sleep(1)\n",
    "                    break\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing: {str(e)}\")\n",
    "                    if attempt == retries - 1:\n",
    "                        last_result = [\n",
    "                            alumni.get('first_name', '') + \" \" + alumni.get('last_name', ''),\n",
    "                            obituary.get('name', ''),\n",
    "                            \"Error\",\n",
    "                            \"No Match\"\n",
    "                        ]\n",
    "                    time.sleep(2**attempt)\n",
    "        \n",
    "        if not match_found:\n",
    "            last_result = [\n",
    "                \"\",  # No alumni matched\n",
    "                obituary.get('name', ''),\n",
    "                0,  # Confidence is 0%\n",
    "                \"No Match\"\n",
    "            ]\n",
    "            print(f\"No match found for {obituary.get('name', '')} with Confidence: 0%\")\n",
    "            results.append(last_result)\n",
    "            \n",
    "            \n",
    "results = []\n",
    "process_with_groq()\n",
    "\n",
    "# Create DataFrame without 'Explanation' column\n",
    "df = pd.DataFrame(results, columns=[\"Alumni Name\", \"Obituary Name\", \"Confidence\", \"Match Status\"])\n",
    "\n",
    "# Print results as table\n",
    "table_str = tabulate(df, headers=\"keys\", tablefmt=\"grid\")\n",
    "\n",
    "print(\"\\n=== Matching Results ===\")\n",
    "print(table_str)\n",
    "\n",
    "# Save results to CSV and TXT (without Explanation)\n",
    "df.to_csv(\"groq_results.csv\", index=False)\n",
    "\n",
    "with open(\"groq_results.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(table_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this concludes all the current AI models used for the testing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Extracting and Saving Ground Truth Data**  \n",
    "\n",
    "This code processes a **matching verification dataset** by extracting relevant fields and saving them in a structured format.  \n",
    "\n",
    "### **Steps:**  \n",
    "1. **Read the Dataset:**  \n",
    "   - Opens the `matching_verification_dataset.csv` file.  \n",
    "   - Extracts the **\"NAME\"** and **\"MATCH\"** columns.  \n",
    "   - Stores the extracted data in a list called `ground_truth`.  \n",
    "\n",
    "2. **Write to a New CSV File:**  \n",
    "   - Creates a new file, `ground_truth.csv`.  \n",
    "   - Writes a header row: `\"Name\", \"Match Status\"`.  \n",
    "   - Iterates through `ground_truth`, writing each entry to the new file.  \n",
    "\n",
    "### **Purpose:**  \n",
    "- This script **cleans and organizes** the data for further analysis.  \n",
    "- The resulting `ground_truth.csv` can be used for **evaluating model performance** by comparing predicted matches with actual matches.  \n",
    "\n",
    "After running the code, a confirmation message is displayed:  \n",
    "> *\"Ground truth CSV has been generated as 'ground_truth.csv'.\"*  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Read the matching verification CSV file and extract the \"NAME\" and \"MATCH\" columns\n",
    "ground_truth = []\n",
    "\n",
    "with open(\"matching_verification_dataset.csv\", \"r\", encoding=\"latin1\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    \n",
    "    for row in reader:\n",
    "        name = row[\"NAME\"]\n",
    "        match_status = row[\"MATCH\"]\n",
    "       \n",
    "        ground_truth.append({\"name\": name, \"match\": match_status})\n",
    "\n",
    "# Now, we'll write this ground truth to a new CSV file\n",
    "with open(\"ground_truth.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Name\", \"Match Status\"]) \n",
    "\n",
    "\n",
    "    for entry in ground_truth:\n",
    "        writer.writerow([entry[\"name\"], entry[\"match\"]])\n",
    "\n",
    "print(\"Ground truth CSV has been generated as 'ground_truth.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluating AI Model Performance for Data Matching**  \n",
    "\n",
    "This script evaluates the accuracy of multiple AI models in predicting data matches. It compares model predictions against a **ground truth dataset** and computes key performance metrics.  \n",
    "\n",
    "### **Steps:**  \n",
    "\n",
    "1. **Load and Preprocess Ground Truth Data:**  \n",
    "   - Reads `ground_truth.csv` using **Pandas**.  \n",
    "   - Converts the `\"Match Status\"` column to a Boolean format for comparison.  \n",
    "\n",
    "2. **Define AI Model Result Files:**  \n",
    "   - A dictionary (`model_files`) maps each model to its corresponding results file.  \n",
    "\n",
    "3. **Evaluation Function (`evaluate_model`)**  \n",
    "   - Reads the model’s predictions from a CSV file.  \n",
    "   - Iterates through each record, comparing predicted matches with actual matches.  \n",
    "   - Computes performance metrics:  \n",
    "     - **True Positives (TP)**  \n",
    "     - **False Positives (FP)**  \n",
    "     - **True Negatives (TN)**  \n",
    "     - **False Negatives (FN)**  \n",
    "     - **Precision, Recall, F1-Score, False Positive Rate (FPR), False Negative Rate (FNR), and Accuracy**  \n",
    "\n",
    "4. **Run Evaluations and Save Results:**  \n",
    "   - Evaluates each model by calling `evaluate_model()`.  \n",
    "   - Stores the results in a DataFrame.  \n",
    "   - Saves the final results to an **Excel file (`model_comparison_results.xlsx`)**, applying formatting for readability.  \n",
    "\n",
    "### **Purpose:**  \n",
    "- This script helps analyze and compare the performance of different AI models for **data matching tasks**.  \n",
    "- The results provide insights into which model achieves the best balance between precision and recall.  \n",
    "\n",
    "After execution, a confirmation message appears:  \n",
    "> *\"Results saved and formatted in 'model_comparison_results.xlsx'.\"*  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating ChatGPT with 200 entries\n",
      "Evaluating Gemini with 10 entries\n",
      "Evaluating Deepseek with 200 entries\n",
      "Evaluating Groq with 200 entries\n",
      "Results saved and formatted in 'model_comparison_results.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ground_truth_df = pd.read_csv(\"ground_truth.csv\")\n",
    "\n",
    "ground_truth_df[\"Match Status\"] = ground_truth_df[\"Match Status\"].astype(str).str.upper() == \"TRUE\"\n",
    "\n",
    "\n",
    "model_files = {\n",
    "    \"ChatGPT\": \"gpt_results.csv\",\n",
    "    \"Gemini\": \"gemini_results.csv\",\n",
    "    \"Deepseek\": \"deepseek_results.csv\",\n",
    "    \"Groq\": \"groq_results.csv\"\n",
    "}\n",
    "\n",
    "\n",
    "def evaluate_model(model_name, filename):\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    print(f\"Evaluating {model_name} with {len(df)} entries\")\n",
    "    \n",
    "    \n",
    "    TP = FP = TN = FN = 0\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        predicted_match = row[\"Match Status\"].strip().upper() == \"MATCH\"\n",
    "        actual_match = ground_truth_df.iloc[i][\"Match Status\"]\n",
    "\n",
    "        # Count True Positives, False Positives, True Negatives, False Negatives\n",
    "        if predicted_match and actual_match:\n",
    "            TP += 1\n",
    "        elif predicted_match and not actual_match:\n",
    "            FP += 1\n",
    "        elif not predicted_match and not actual_match:\n",
    "            TN += 1\n",
    "        elif not predicted_match and actual_match:\n",
    "            FN += 1\n",
    "\n",
    "    total_comparisons = TP + FP + TN + FN\n",
    "\n",
    "    # Compute metrics with safe division\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    fpr = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "    fnr = FN / (FN + TP) if (FN + TP) > 0 else 0\n",
    "    accuracy = (TP + TN) / total_comparisons if total_comparisons > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"TP\": TP, \"FP\": FP, \"TN\": TN, \"FN\": FN,\n",
    "        \"Precision\": round(precision, 4),\n",
    "        \"Recall\": round(recall, 4),\n",
    "        \"F1 Score\": round(f1_score, 4),\n",
    "        \"FPR\": round(fpr, 4),\n",
    "        \"FNR\": round(fnr, 4),\n",
    "        \"Accuracy\": round(accuracy, 4),\n",
    "        \"Comparisons\": total_comparisons\n",
    "    }\n",
    "\n",
    "evaluation_results = []\n",
    "\n",
    "for model_name, file in model_files.items():\n",
    "    # Read the model results CSV\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    evaluation_results.append(evaluate_model(model_name, file))\n",
    "\n",
    "\n",
    "eval_df = pd.DataFrame(evaluation_results)\n",
    "\n",
    "# Write the evaluation results to an Excel file\n",
    "with pd.ExcelWriter(\"model_comparison_results.xlsx\", engine='xlsxwriter') as writer:\n",
    "    eval_df.to_excel(writer, index=False, sheet_name=\"Model Comparison\")\n",
    "\n",
    "    workbook  = writer.book\n",
    "    worksheet = writer.sheets[\"Model Comparison\"]\n",
    "\n",
    "    header_format = workbook.add_format({'bold': True, 'align': 'center', 'valign': 'vcenter', 'border': 1})\n",
    "    cell_format = workbook.add_format({'align': 'center', 'valign': 'vcenter', 'border': 1})\n",
    "\n",
    "    for col_num, value in enumerate(eval_df.columns.values):\n",
    "        worksheet.write(0, col_num, value, header_format)\n",
    "\n",
    "    for row_num in range(1, len(eval_df) + 1):\n",
    "        for col_num in range(len(eval_df.columns)):\n",
    "            worksheet.write(row_num, col_num, eval_df.iloc[row_num - 1, col_num], cell_format)\n",
    "\n",
    "print(\"Results saved and formatted in 'model_comparison_results.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model    |   TP |   FP |   TN |   FN |   Precision |   Recall |   F1 Score |   FPR |   FNR |   Accuracy |   Comparisons |\n",
      "|:---------|-----:|-----:|-----:|-----:|------------:|---------:|-----------:|------:|------:|-----------:|--------------:|\n",
      "| ChatGPT  |   93 |    2 |   98 |    7 |      0.9789 |     0.93 |     0.9538 |  0.02 |  0.07 |      0.955 |           200 |\n",
      "| Gemini   |    4 |    2 |    3 |    1 |      0.6667 |     0.8  |     0.7273 |  0.4  |  0.2  |      0.7   |            10 |\n",
      "| Deepseek |   98 |    6 |   94 |    2 |      0.9423 |     0.98 |     0.9608 |  0.06 |  0.02 |      0.96  |           200 |\n",
      "| Groq     |   86 |    7 |   93 |   14 |      0.9247 |     0.86 |     0.8912 |  0.07 |  0.14 |      0.895 |           200 |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file\n",
    "eval_df = pd.read_excel(\"model_comparison_results.xlsx\", sheet_name=\"Model Comparison\")\n",
    "\n",
    "# Convert to Markdown format\n",
    "markdown_table = eval_df.to_markdown(index=False)\n",
    "\n",
    "# Print Markdown format (copy this and paste it into a Markdown cell)\n",
    "print(markdown_table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
